{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3010c3",
   "metadata": {},
   "source": [
    "# RAG: the first part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53195b1b",
   "metadata": {},
   "source": [
    "## what is RAGðŸ§?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61181888",
   "metadata": {},
   "source": [
    "RAG, or Retrieval-Augmented Generation, is a technique that combines the strengths of search engines and language models. It first retrieves relevant information from a large collection of documents, then uses that information to generate more accurate and informed responses.\n",
    "\n",
    "![RAG illustration: Retrieval and Generation workflow from langchain docs](https://python.langchain.com/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png)\n",
    "\n",
    "*In the illustration above, RAG retrieves supporting documents before generating an answer, ensuring responses are grounded in real data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc8e0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb99bc91",
   "metadata": {},
   "source": [
    "## let's create a sample RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cbc92",
   "metadata": {},
   "source": [
    "before start the implementation we need to have data in order to feed our application the needed that for this so under `/dataset` you will find a collection of markdown files that contain needed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c9742",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d3f176f",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45bf9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67613fba",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2da9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "MODEL = \"gpt-4o\"\n",
    "\n",
    "sickness_folders = glob.glob(\"datasets/*/\")\n",
    "\n",
    "for folder_path in sickness_folders:\n",
    "    sickness_name = os.path.basename(folder_path.rstrip('/'))\n",
    "    \n",
    "    symptom_file = os.path.join(folder_path, \"symptoms.md\")\n",
    "    treatment_file = os.path.join(folder_path, \"treatment.md\")\n",
    "    \n",
    "    sickness_data = {\n",
    "        \"name\": sickness_name,\n",
    "        \"symptoms\": \"\",\n",
    "        \"treatment\": \"\"\n",
    "    }\n",
    "    \n",
    "    if os.path.exists(symptom_file):\n",
    "        try:\n",
    "            with open(symptom_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                sickness_data[\"symptoms\"] = f.read()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    if os.path.exists(treatment_file):\n",
    "        try:\n",
    "            with open(treatment_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                sickness_data[\"treatment\"] = f.read()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    if sickness_data[\"symptoms\"] or sickness_data[\"treatment\"]:\n",
    "        full_document = f\"DISEASE: {sickness_name.upper()}\\n\\n\"\n",
    "        \n",
    "        if sickness_data[\"symptoms\"]:\n",
    "            full_document += \"SYMPTOMS:\\n\" + sickness_data[\"symptoms\"] + \"\\n\\n\"\n",
    "        \n",
    "        if sickness_data[\"treatment\"]:\n",
    "            full_document += \"TREATMENT:\\n\" + sickness_data[\"treatment\"] + \"\\n\\n\"\n",
    "        \n",
    "        context[sickness_name] = full_document\n",
    "        context[f\"{sickness_name}_symptoms\"] = sickness_data[\"symptoms\"]\n",
    "        context[f\"{sickness_name}_treatment\"] = sickness_data[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a medical expert assistant that answers questions about diseases, their symptoms and treatments.\n",
    "You only use information provided in the medical documents from your knowledge base.\n",
    "\n",
    "Important instructions:\n",
    "- Provide precise and well-structured answers\n",
    "- Clearly distinguish between symptoms and treatments\n",
    "- If you cannot find information in the provided context, state it clearly\n",
    "- Never make medical diagnoses - always recommend consulting a healthcare professional\n",
    "- Never invent medical information that is not in the provided documents\n",
    "- Organize your responses clearly with sections for symptoms and treatments when appropriate\n",
    "\n",
    "WARNING: The information provided is for informational purposes only and does not replace professional medical advice.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8de72c",
   "metadata": {},
   "source": [
    "## Context Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9f16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    relevant_context = []\n",
    "    message_lower = message.lower()\n",
    "    \n",
    "    symptom_keywords = [\"symptom\", \"symptoms\", \"sign\", \"signs\", \"manifestation\", \"present\"]\n",
    "    treatment_keywords = [\"treatment\", \"treatments\", \"treat\", \"cure\", \"medicine\", \"remedy\", \"therapy\"]\n",
    "    \n",
    "    is_symptom_query = any(keyword in message_lower for keyword in symptom_keywords)\n",
    "    is_treatment_query = any(keyword in message_lower for keyword in treatment_keywords)\n",
    "    \n",
    "    for document_name, document_content in context.items():\n",
    "        score = 0\n",
    "        \n",
    "        disease_name = document_name.replace(\"_symptoms\", \"\").replace(\"_treatment\", \"\")\n",
    "        if disease_name.lower() in message_lower:\n",
    "            score += 10\n",
    "        \n",
    "        message_words = [word for word in message_lower.split() if len(word) > 3]\n",
    "        document_content_lower = document_content.lower()\n",
    "        \n",
    "        matching_words = sum(1 for word in message_words if word in document_content_lower)\n",
    "        if len(message_words) > 0:\n",
    "            word_match_ratio = matching_words / len(message_words)\n",
    "            score += word_match_ratio * 5\n",
    "        \n",
    "        if is_symptom_query and document_name.endswith(\"_symptoms\"):\n",
    "            score += 3\n",
    "        elif is_treatment_query and document_name.endswith(\"_treatment\"):\n",
    "            score += 3\n",
    "        elif not document_name.endswith(\"_symptoms\") and not document_name.endswith(\"_treatment\"):\n",
    "            score += 1\n",
    "        \n",
    "        if score >= 2:\n",
    "            relevant_context.append({\n",
    "                \"content\": document_content,\n",
    "                \"name\": document_name,\n",
    "                \"score\": score\n",
    "            })\n",
    "    \n",
    "    relevant_context.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    top_documents = relevant_context[:5]\n",
    "    \n",
    "    return [doc[\"content\"] for doc in top_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380da1e",
   "metadata": {},
   "source": [
    "## Context Addition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3add4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(message):\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    \n",
    "    if relevant_context:\n",
    "        message += \"\\n\\n=== RELEVANT MEDICAL INFORMATION ===\\n\"\n",
    "        message += \"The following information from your medical knowledge base may be helpful:\\n\\n\"\n",
    "        \n",
    "        for i, context_doc in enumerate(relevant_context, 1):\n",
    "            if \"SYMPTOMS:\" in context_doc and \"TREATMENT:\" in context_doc:\n",
    "                doc_type = \"COMPLETE RECORD\"\n",
    "            elif \"SYMPTOMS:\" in context_doc:\n",
    "                doc_type = \"SYMPTOMS\"\n",
    "            elif \"TREATMENT:\" in context_doc:\n",
    "                doc_type = \"TREATMENT\"\n",
    "            else:\n",
    "                doc_type = \"DOCUMENT\"\n",
    "            \n",
    "            message += f\"{doc_type} {i}:\\n\"\n",
    "            message += f\"{context_doc}\\n\"\n",
    "            message += \"-\" * 60 + \"\\n\\n\"\n",
    "        \n",
    "        message += \"=== END OF MEDICAL INFORMATION ===\\n\\n\"\n",
    "        message += \"Response instructions:\\n\"\n",
    "        message += \"- Base your response only on the information above\\n\"\n",
    "        message += \"- Structure your response in clear sections (symptoms, treatments, etc.)\\n\"\n",
    "        message += \"- Always include the medical consultation warning\\n\"\n",
    "        message += \"- If the requested information is not available, state it clearly\\n\"\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543f879",
   "metadata": {},
   "source": [
    "## OpenAI API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d32d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5f8a4",
   "metadata": {},
   "source": [
    "## Main Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b006d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    try:\n",
    "        messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        \n",
    "        for msg in history:\n",
    "            messages.append(msg)\n",
    "        \n",
    "        enriched_message = add_context(message)\n",
    "        messages.append({\"role\": \"user\", \"content\": enriched_message})\n",
    "        \n",
    "        stream = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        response = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                response += chunk.choices[0].delta.content\n",
    "                yield response\n",
    "                \n",
    "    except Exception as e:\n",
    "        yield f\"Error generating response: {str(e)}\"\n",
    "\n",
    "def simple_chat_test(message):\n",
    "    try:\n",
    "        enriched_message = add_context(message)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": enriched_message}\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f0f6d",
   "metadata": {},
   "source": [
    "## RAG System Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "267cd9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'client' in globals():\n",
    "    test_questions = [\n",
    "        \"What diseases are available in the database?\",\n",
    "        \"What are the symptoms of flu?\",\n",
    "        \"How to treat migraine?\",\n",
    "        \"What are the signs of diabetes?\",\n",
    "        \"What is the treatment for hypertension?\",\n",
    "        \"Symptoms and treatment of asthma?\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        relevant_context = get_relevant_context(question)\n",
    "        \n",
    "        try:\n",
    "            response = simple_chat_test(question)\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f30af",
   "metadata": {},
   "source": [
    "## Gradio Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'client' in globals() and client:\n",
    "    diseases = [name for name in context.keys() if not name.endswith('_symptoms') and not name.endswith('_treatment')]\n",
    "    \n",
    "    chat_interface = gr.ChatInterface(\n",
    "        fn=chat,\n",
    "        type=\"messages\",\n",
    "        title=\"Medical Assistant RAG\",\n",
    "        description=f\"\"\"\n",
    "        Ask questions about diseases, symptoms and treatments!\n",
    "        \n",
    "        Knowledge base: {len(diseases)} documented diseases\n",
    "        Total documents: {len(context)} (including symptoms and treatments)\n",
    "        \n",
    "        WARNING: The information provided is for informational purposes only. \n",
    "        Always consult a healthcare professional for proper diagnosis and treatment.\n",
    "        \"\"\",\n",
    "        examples=[\n",
    "            \"What diseases are available in your database?\",\n",
    "            \"What are the symptoms of flu?\",\n",
    "            \"How to treat migraine?\",\n",
    "            \"Symptoms and treatment of diabetes?\",\n",
    "            \"What is hypertension?\",\n",
    "            \"How to recognize an asthma attack?\",\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    chat_interface.launch(\n",
    "        share=False,\n",
    "        debug=True,\n",
    "        show_error=True,\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7860\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d49a6",
   "metadata": {},
   "source": [
    "## Conclusion and Possible Improvements\n",
    "\n",
    "### What we accomplished:\n",
    "- Automatic loading of all files from the `datasets` folder\n",
    "- Context search system based on keywords  \n",
    "- Integration with OpenAI API for response generation\n",
    "- Interactive chat interface with Gradio\n",
    "- Response streaming for better user experience\n",
    "\n",
    "### Possible improvements:\n",
    "1. **Semantic search**: Use embeddings (like OpenAI Embeddings) for more precise search\n",
    "2. **Intelligent chunking**: Divide long documents into smaller chunks\n",
    "3. **Vector database**: Use Chroma, Pinecone, or FAISS for better search performance\n",
    "4. **Preprocessing**: Clean and structure data before indexing\n",
    "5. **Metrics**: Add metrics to evaluate result relevance\n",
    "6. **Cache**: Cache frequent results to improve performance\n",
    "\n",
    "### Next steps:\n",
    "- Test with different types of questions\n",
    "- Optimize the context search function\n",
    "- Add more documents to the knowledge base\n",
    "- Implement advanced semantic search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
